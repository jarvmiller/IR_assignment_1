{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text (e.g. use the nltk.word_tokenize() function in the NLTK package)\n",
    "and compute the frequency of words. Then, plot the frequency distribution of words in each collection after the\n",
    "removal of the stopwords: x-axis - word frequency (number of times a word appears in the collection); y-axis\n",
    "-proportion of words with this frequency. Plot the distributions on a log-log scale. Does each plot look like a\n",
    "power-law distribution? Are the two distributions similar or different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the two collections more rigorously. Report the following properties of each\n",
    "collection. Can you explain these differences based on the nature of the two collections? (20 points) (You can\n",
    "use the nltk.pos tag() function of the NLTK package for part of speech tagging.)\n",
    "(a) frequency of stopwords (percentage of the word occurrences that are stopwords.);\n",
    "(b) percentage of capital letters;\n",
    "(c) average number of characters per word;\n",
    "(d) percentage of nouns, adjectives, verbs, adverbs, and pronouns;\n",
    "(e) the top 10 nouns, top 10 verbs, and top 10 adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to summarize each document with a few words. However, picking the most\n",
    "frequently used words in each document would be a bad idea, since they are more likely to appear in other\n",
    "document as well. Instead, we pick the words with the highest TF-IDF weights in each document.\n",
    "In this problem, term frequency (TF) and inverse document frequency (IDF) are defined as:\n",
    "- *TF(t, d) = log(c(t, d) + 1)*\n",
    "- *IDF(t) = 1 + log(N/k).*\n",
    "\n",
    "c(t, d) is the frequency count of term t in doc d, N is the total number of documents in the collection, and k is\n",
    "the document frequency of term t in the collection.\n",
    "For each of the first 10 documents in the EHR collection, print out the 5 words that have the highest TF-IDF\n",
    "weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the class, TF-IDF is a common way to weight the terms in each document. It\n",
    "can also be easily calculated from the inverted index, since TF can be obtained from the postings and IDF can\n",
    "be summarized as a dictionary. Could you think of another weighting that cannot be calculated directly from\n",
    "inverted index? What is the advantage of such a weighting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
